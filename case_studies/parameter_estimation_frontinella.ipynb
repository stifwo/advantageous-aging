{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c350fd45-8cf3-40f6-9758-568da8362c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import operator\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, '../') # The following modules are in the directory above\n",
    "from cohort_model import (\n",
    "    run_cohort_simulation,\n",
    "    HYP_WILDTYPE, \n",
    "    MUT_CAPTIVITY,\n",
    ")\n",
    "from figures import ROOT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b46820-0ece-48b2-bdcc-fddbcc34f600",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Parameter estimation for case study 1 (*Frontinella pyramitela*)\n",
    "\n",
    "We have estimated model parameters using least squares fitting. Typically, such problems are solved with utilities such as [`scipy.optimize.curve_fit`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html). However, our model function is non-analytical, due to its stochasticity. Thus, analytical curve fitting methods are not possible to use, and we have instead opted for a simple iterative search in the parameter space.\n",
    "\n",
    "We encourage examining other methods of exploring the parameter space. This could potentially be a conventional space search algorithm, or an evolutionary algorithm framework such as [DEAP](https://deap.readthedocs.io/en/master/). If you develop a more efficient/optimal method, we welcome you to submit a pull request on GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cd99b4-6d4d-4f64-8520-bfb3a17bb468",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Note:** The parameter values used in figures 1 and 2 were obtained during an earlier least squares fitting. In restructuring the code for publication we have also improved the fitting procedure and obtained new and better values. However, these are not used in the figures in order to produce results matching those in the published paper (which could not be updated by the time we obtained the better fit)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdba215a-7682-4582-9299-cce2a269f11b",
   "metadata": {},
   "source": [
    "## Estimating $\\alpha$ and $\\kappa$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15b6091c-5da7-4783-82c7-56972fec3eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "individual_count = 1000 \n",
    "repetition_count = 100  \n",
    "\n",
    "t_m_captivity = 202  # Max t for curve fitting (last x data point = 201) \n",
    "t_m_wt = 101         # Max t for curve fitting (last x data point = 100)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f2d845b-11c0-4082-9637-fcc37c664b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "captivity_x = np.genfromtxt(f'{ROOT_DIR}/data/austad_1989/captivity_x.txt')\n",
    "captivity_y = np.genfromtxt(f'{ROOT_DIR}/data/austad_1989/captivity_y.txt')\n",
    "\n",
    "xdata = np.round(captivity_x).astype('int64') # In order to use for indexing\n",
    "ydata = captivity_y * individual_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28dd3166-974c-483e-97b1-3acfec9800c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 43min 12s, sys: 2h 45min 35s, total: 5h 28min 48s\n",
      "Wall time: 5h 31min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_count = len(xdata)\n",
    "\n",
    "fit = []\n",
    "# TODO: The population is set to mutant captivity in order to \n",
    "for alpha in np.arange(0.0002, 0.0003, 0.00001): \n",
    "    for kappa in np.arange(0.02, 0.04, 0.0001): \n",
    "        hazard_rate_params = dict(alpha=alpha, kappa=kappa, population=MUT_CAPTIVITY)\n",
    "        population_survivorship = run_cohort_simulation(\n",
    "            repetition_count, \n",
    "            individual_count, \n",
    "            hazard_rate_params, \n",
    "            t_m_captivity\n",
    "        )\n",
    "        mean = np.mean(population_survivorship, axis=0)[xdata]\n",
    "        squares = [(mean[index] - ydata[index])**2 for index in range(data_count)] \n",
    "        fit.append((alpha, kappa, sum(squares)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a739ba8-2d60-426c-b7c8-ed54e7d3e45f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0002, 0.03349999999999992, 1093.8604000000005)\n",
      "(0.00021, 0.03309999999999992, 1130.759000000001)\n",
      "(0.0002, 0.03359999999999992, 1143.5305000000028)\n",
      "(0.00021, 0.033199999999999924, 1175.9992999999972)\n",
      "(0.0002, 0.03369999999999992, 1192.7424999999978)\n",
      "(0.00022, 0.03289999999999992, 1194.2436)\n",
      "(0.0002, 0.03379999999999991, 1248.6812999999984)\n",
      "(0.00021, 0.033399999999999916, 1268.3848999999973)\n",
      "(0.00022, 0.032699999999999924, 1297.2533999999987)\n",
      "(0.00021, 0.03329999999999992, 1315.9933999999994)\n"
     ]
    }
   ],
   "source": [
    "best_fits = sorted(fit, key=operator.itemgetter(2))\n",
    "print(*best_fits[0:10], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d431e58c-404c-4f33-b74b-166ed05fa5e7",
   "metadata": {},
   "source": [
    "## Estimating $\\epsilon$ and $h_{wt}(t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aa3a554-e111-435e-808b-47c0475a1d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_wild = np.genfromtxt(f'{ROOT_DIR}/data/austad_1989/wild_x.txt')\n",
    "y_wild = np.genfromtxt(f'{ROOT_DIR}/data/austad_1989/wild_y.txt')\n",
    "\n",
    "xdata_w = np.round(x_wild).astype('int64') # In order to use for indexing\n",
    "ydata_w = y_wild * individual_count\n",
    "\n",
    "xdata_w = xdata_w[:-2] # In order not to fit to the last two data points\n",
    "ydata_w = ydata_w[:-2] # In order not to fit to the last two data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38fcdcc2-af9e-4201-aeb8-d16f9866d6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.9 s, sys: 18.5 s, total: 41.3 s\n",
      "Wall time: 41.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = len(xdata_w)\n",
    "\n",
    "fit = []\n",
    "# TODO: The population is set to the hypothetical wild type, in order to use the \n",
    "for prod_wt in np.arange(0.0378, 0.0382, 0.000025):  # prod_wt = (1 - epsilon) * h_wt\n",
    "    hazard_rate_params = dict(hazard_rate_wt=prod_wt, population=HYP_WILDTYPE)\n",
    "    population_survivorship = run_cohort_simulation(\n",
    "        repetition_count, \n",
    "        individual_count, \n",
    "        hazard_rate_params, \n",
    "        t_m_wt,\n",
    "    )\n",
    "    mean = np.mean(population_survivorship, axis=0)[xdata_w]\n",
    "    squares = [(mean[i] - ydata_w[i])**2 for i in range(n)] # Not fitting to last two data points\n",
    "    fit.append((prod_wt, sum(squares)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c846087-9c42-46de-a108-1d79e126d5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.03797499999999998, 1045.1383999999973)\n",
      "(0.03789999999999999, 1054.7347999999981)\n",
      "(0.037924999999999986, 1066.2092999999975)\n",
      "(0.0378, 1075.0033999999994)\n",
      "(0.03799999999999998, 1090.0588999999966)\n",
      "(0.03787499999999999, 1103.3432999999966)\n",
      "(0.038024999999999975, 1105.7740999999994)\n",
      "(0.037849999999999995, 1115.4339999999977)\n",
      "(0.037825, 1126.9093999999943)\n",
      "(0.037949999999999984, 1133.3473999999987)\n"
     ]
    }
   ],
   "source": [
    "best_fits = sorted(fit, key=operator.itemgetter(1))\n",
    "print(*best_fits[0:10], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d61c53d-9dab-4a0c-9e17-c1f86296a17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon = 0.01, h_wt = 0.03835858585858584\n",
      "epsilon = 0.02, h_wt = 0.03874999999999998\n",
      "epsilon = 0.03, h_wt = 0.039149484536082454\n",
      "epsilon = 0.04, h_wt = 0.03955729166666665\n"
     ]
    }
   ],
   "source": [
    "prod_wt = best_fits[0][0]\n",
    "for epsilon in np.arange(0.01, 0.05, 0.01):\n",
    "    h_wt = prod_wt / (1 - epsilon)\n",
    "    print(f'epsilon = {epsilon}, h_wt = {h_wt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fd3beb-9d3c-45e0-a58a-6c6cb6e57e67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
